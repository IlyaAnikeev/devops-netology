# Домашнее задание к занятию "13.Системы мониторинга"
<details>
<summary>Обязательные задания:</summary>

1. Вас пригласили настроить мониторинг на проект. На онбординге вам рассказали, что проект представляет из себя 
платформу для вычислений с выдачей текстовых отчетов, которые сохраняются на диск. Взаимодействие с платформой 
осуществляется по протоколу http. Также вам отметили, что вычисления загружают ЦПУ. Какой минимальный набор метрик вы
выведите в мониторинг и почему?
#
2. Менеджер продукта посмотрев на ваши метрики сказал, что ему непонятно что такое RAM/inodes/CPUla. Также он сказал, 
что хочет понимать, насколько мы выполняем свои обязанности перед клиентами и какое качество обслуживания. Что вы 
можете ему предложить?
#
3. Вашей DevOps команде в этом году не выделили финансирование на построение системы сбора логов. Разработчики в свою 
очередь хотят видеть все ошибки, которые выдают их приложения. Какое решение вы можете предпринять в этой ситуации, 
чтобы разработчики получали ошибки приложения?
#
4. Вы, как опытный SRE, сделали мониторинг, куда вывели отображения выполнения SLA=99% по http кодам ответов. 
Вычисляете этот параметр по следующей формуле: summ_2xx_requests/summ_all_requests. Данный параметр не поднимается выше 
70%, но при этом в вашей системе нет кодов ответа 5xx и 4xx. Где у вас ошибка?
#
5. Опишите основные плюсы и минусы pull и push систем мониторинга.
#
6. Какие из ниже перечисленных систем относятся к push модели, а какие к pull? А может есть гибридные?

    - Prometheus 
    - TICK
    - Zabbix
    - VictoriaMetrics
    - Nagios
#
7. Склонируйте себе [репозиторий](https://github.com/influxdata/sandbox/tree/master) и запустите TICK-стэк, 
используя технологии docker и docker-compose.

В виде решения на это упражнение приведите скриншот веб-интерфейса ПО chronograf (`http://localhost:8888`). 

P.S.: если при запуске некоторые контейнеры будут падать с ошибкой - проставьте им режим `Z`, например
`./data:/var/lib:Z`
#
8. Перейдите в веб-интерфейс Chronograf (http://localhost:8888) и откройте вкладку Data explorer.
        
    - Нажмите на кнопку Add a query
    - Изучите вывод интерфейса и выберите БД telegraf.autogen
    - В `measurments` выберите cpu->host->telegraf-getting-started, а в `fields` выберите usage_system. Внизу появится график утилизации cpu.
    - Вверху вы можете увидеть запрос, аналогичный SQL-синтаксису. Поэкспериментируйте с запросом, попробуйте изменить группировку и интервал наблюдений.

Для выполнения задания приведите скриншот с отображением метрик утилизации cpu из веб-интерфейса.
#
9. Изучите список [telegraf inputs](https://github.com/influxdata/telegraf/tree/master/plugins/inputs). 
Добавьте в конфигурацию telegraf следующий плагин - [docker](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/docker):
```
[[inputs.docker]]
  endpoint = "unix:///var/run/docker.sock"
```

Дополнительно вам может потребоваться донастройка контейнера telegraf в `docker-compose.yml` дополнительного volume и 
режима privileged:
```
  telegraf:
    image: telegraf:1.4.0
    privileged: true
    volumes:
      - ./etc/telegraf.conf:/etc/telegraf/telegraf.conf:Z
      - /var/run/docker.sock:/var/run/docker.sock:Z
    links:
      - influxdb
    ports:
      - "8092:8092/udp"
      - "8094:8094"
      - "8125:8125/udp"
```

После настройке перезапустите telegraf, обновите веб интерфейс и приведите скриншотом список `measurments` в 
веб-интерфейсе базы telegraf.autogen . Там должны появиться метрики, связанные с docker.

Факультативно можете изучить какие метрики собирает telegraf после выполнения данного задания.
</details>
<details>
<summary>Дополнительное задание (со звездочкой*) - необязательно к выполнению:</summary>

1. Вы устроились на работу в стартап. На данный момент у вас нет возможности развернуть полноценную систему 
мониторинга, и вы решили самостоятельно написать простой python3-скрипт для сбора основных метрик сервера. Вы, как 
опытный системный-администратор, знаете, что системная информация сервера лежит в директории `/proc`. 
Также, вы знаете, что в системе Linux есть  планировщик задач cron, который может запускать задачи по расписанию.

Суммировав все, вы спроектировали приложение, которое:
- является python3 скриптом
- собирает метрики из папки `/proc`
- складывает метрики в файл 'YY-MM-DD-awesome-monitoring.log' в директорию /var/log 
(YY - год, MM - месяц, DD - день)
- каждый сбор метрик складывается в виде json-строки, в виде:
  + timestamp (временная метка, int, unixtimestamp)
  + metric_1 (метрика 1)
  + metric_2 (метрика 2)
  
     ...
     
  + metric_N (метрика N)
  
- сбор метрик происходит каждую 1 минуту по cron-расписанию

Для успешного выполнения задания нужно привести:

а) работающий код python3-скрипта,

б) конфигурацию cron-расписания,

в) пример верно сформированного 'YY-MM-DD-awesome-monitoring.log', имеющий не менее 5 записей,

P.S.: количество собираемых метрик должно быть не менее 4-х.
P.P.S.: по желанию можно себя не ограничивать только сбором метрик из `/proc`.

2. В веб-интерфейсе откройте вкладку `Dashboards`. Попробуйте создать свой dashboard с отображением:

    - утилизации ЦПУ
    - количества использованного RAM
    - утилизации пространства на дисках
    - количество поднятых контейнеров
    - аптайм
    - ...
    - фантазируйте)
    
    ---
</details>
<details>
<summary>Как оформить ДЗ?</summary>

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.
</details>

---

# Ответ

# Домашнее задание к занятию "13.Системы мониторинга"

## Обязательные задания

1. Вас пригласили настроить мониторинг на проект. На онбординге вам рассказали, что проект представляет из себя 
платформу для вычислений с выдачей текстовых отчетов, которые сохраняются на диск. Взаимодействие с платформой 
осуществляется по протоколу http. Также вам отметили, что вычисления загружают ЦПУ. Какой минимальный набор метрик вы
выведите в мониторинг и почему?
#
<details>
<summary>&#x1F538;CPU. Для мониторинга использования процессорного времени на сервере выставляются два базовых алерта:</summary>

- CPU idle < 10% в течение 10 минут;
- CPU Load Average превышает количество доступных процессоров и не равно 0 в течение 5 минут.

На их основе можно идентифицировать критически высокую нагрузку на сервере (при этом фиксируем не разовые скачки, которые в большинстве случаев являются нормой, а постоянно высокий уровень в течение какого-то времени — в нашем случае это 10 минут), а также недоступность сервера.
</details>
<details>
<summary>&#x1F538;Оперативная память. В большинстве случаев для определения высокой загруженности данной подсистемы и возможного начала деградации мы выставляем следующие алерты:</summary>

- заполнение SWAP > 90% (актуально для версий ядра Linux младше третей);
- активная запись в SWAP (swapin > 1 Мбайт/с) в течение 2-5 минут (актуально для новых версий ядра Linux);
- используемая оперативная память > 85%.

Очевидно, что чем выше нагрузка на оперативную память и ближе к стопроцентной утилизации, тем выше вероятность «тормозов» в работе ПО, запущенного на сервере, или даже его «умирания» по OOM. Данные значения, достаточно универсальны и подходят в большинстве случаев, но, конечно, могут различаться — в зависимости от характера приложений, запущенных на сервере. Их можно использовать как начальное приближение и скорректировать, чтобы отрегулировать интенсивность алертинга.
</details>
<details>
<summary>&#x1F538;Дисковая подсистема. Основные алерты по метрикам в дисковой подсистеме это:</summary>

- нагрузка на диск (iostat) > 95% в течение 1 часа;
- free inodes (по каждому разделу) <10%;
- свободное место на диске (по каждому разделу) <10% + дополнительный алерт < 5%.

Слишком высокая нагрузка на дисковую подсистему чревата полной деградацией всей системы. Например, если снизится скорость чтения/записи данных на диск, то это может повлиять на скорость формирования кеша и работы с БД. А если кончится место или свободные inodes, то запись на диск полностью остановится, что приведёт к блокировке работы всего сервиса или потере чувствительных данных. А в некоторых случаях к «битым» базам данных, которые админы будут долго и мучительно пытаться восстановить.

Однако, конфигурируя алерты на процент свободного места, стоит учесть, какое ПО на сервере. Например, если этот сервер делает бэкапы, т.е. бывает периодическое резкое увеличение объёма данных, или на нём работает ElasticSearch, то лучше иметь свободными 15% от большого диска. Если же ничего подобного там нет или объём дисковой подсистемы измеряется десятками терабайт, то скорее всего алерт на 10% — избыточная перестраховка, и порог срабатывания можно смело снизить до 3−5%.

Также, с точки зрения мониторинга файловой системы, рекомендуется следить за состоянием маунтов (сетевых дисков) и настроить алерты, во-первых, на наличие самого маунта, во-вторых, на корректность работы подмонтированной файловой системы.
</details>
<details>
<summary>&#x1F538;Дополнительный мониторинг дисков:</summary>

- результат SMART-теста диска отличается от passed — если тест не пройден (статус failed), диск может быть неисправен, и есть риск потерять данные;
- количество поврежденных (переназначенных) секторов HDD > 1;
- процент износа SSD — < 10% от полезного срока службы. Как правило производитель определяет порог, после которого диск переходит в read-only режим;
- процент использования NVMe > 90%;
- объем резервной области NVMe < 15%;
- ошибки целостности данных NVMe > 1.
</details>
<details>
<summary>&#x1F538;RAID. Мониторинг RAID-массивов зависит от наличия контроллера, но необходимый минимум, который позволяет обеспечить целостность данных, для обоих случаев один и состоит из трёх пунктов:</summary>

- алерт на «вылет» диска из рейда;
- алерт, срабатывающий в начале проверки/синхронизации после восстановления диска в массиве (помогает понять, что резкие скачки в нагрузке на CPU или память временные и не являются проблемой);
- количество битых дисков > 1.

Если контроллер имеется, то дополнительно имеет смысл поставить алерты на различные ошибки, здоровье, кеш, состояние батареи и т.д.
</details>
<details>
<summary>&#x1F538;Синхронизация времени на сервере с эталонным. Рассинхронизация времени иногда приводит к сложнодиагностируемым ошибкам как в серверном ПО, так и в клиентских приложениях. Поэтому необходимо мониторить её, запрашивая статус используемых на сервере утилит синхронизации времени, например, ntpd, chronyd или systemd-timesyncd, и используем алерты следующего вида:</summary>

- > 500 миллисекунд в течение 5 минут;
- < 500 миллисекунд в течение 5 минут.

Большая рассинхронизация иногда приводит к интересным последствиям. Например, встречаются ошибки в репликации данных между двумя базами (как в схеме мастер-слейв так и мастер-мастер) или получение логов «из будущего». Также отставание времени на сервере может неприятно повлиять на работу интернет-магазинов: например крон-задание, которое должно запускаться ровно в полночь, из-за рассинхрона времени запустится раньше или позже обычного и нарушит формирование отчетов — как внутренних, так и внешних, скажем, для налоговой.
</details>
<details>
<summary>&#x1F538;Сетевые интерфейсы. Мониторить объем входящего и исходящего трафика может быть необходимо из-за специфики тарификации трафика или когда заведомо известно о проблемах с сетевым каналом. Кроме того, если сервер используется для раздачи контента, резкие скачки нагрузки на канал могут сигнализировать о какой-либо аномалии, например, DDoS-атаке. Отслеживаем следующие алерты на сетевые интерфейсы:</summary>

- входящая нагрузка >75% или >90% от лимита;
- исходящая нагрузка >75% или >90% от лимита;
- алерт на резкий (и нехарактерный при этом) скачок входящего или исходящего трафика.

Это «прожиточный минимум», база, с которой необходимо конфигурировать мониторинг и которая полезна для 99% серверов и виртуальных машин.
Нет большого смысла мониторить те метрики, с которыми непонятно что делать или которые дороже собирать и обрабатывать, чем могут быть потенциальные издержки от отсутствия мониторинга на них. А алерты не должны возникать каждые две секунды и сливаться в белый шум.
</details>

#
2. Менеджер продукта посмотрев на ваши метрики сказал, что ему непонятно что такое RAM/inodes/CPUla. Также он сказал, 
что хочет понимать, насколько мы выполняем свои обязанности перед клиентами и какое качество обслуживания. Что вы 
можете ему предложить?
#
- **Оперативная память (RAM, ОЗУ)** — это тип памяти, в котором во время работы компьютера хранится выполняемый машинный код и данные, которые в этот момент обрабатывает процессор. Оперативная память отличается от устройств постоянной памяти, например, жёстких дисков или твердотельных накопителей, большей скоростью работы. Она энергозависима: если прекратить подачу электропитания, например, выключить компьютер, вся хранящаяся в оперативной памяти информация стирается.
- **Inodes, или индексные дескрипторы («описатели»)** — это структуры данных в системах Unix, используемые для хранения информации о файлах и каталогах. Так как дескрипторы являются, по сути, данными о данных, их также называют метаданными.
- **CPUla** - средняя загрузка (англ. load average), показатель загруженности вычислительных мощностей, используемый в ряде операционных систем. В Unix-подобных системах, как правило, отображается в виде трёх значений, которые представляют собой усреднённые величины за последние 1, 5 и 15 минут. Чем ниже эта величина, тем менее загружены вычислительные мощности.

  - Централизовать данные. Отслеживать метрики становится сложнее, если есть несколько источников данных. Когда разные команды/члены команд руководствуются данными из различных источников, то есть риск получить недопонимание в коллективе.
  - Делиться данными. Общие данные – очень мощная вещь. Предоставить всем членам команды возможность принимать правильные, основанные на данных, решения, дав им доступ к необходимым метрикам.
  - Визуализировать свои данные. Использование инструментов визуализации данных превращает сложные числа в простые визуальные элементы. Это делает их понятными для всех членов команды, а не только для тех, кто хорошо знаком с этими данными.
  - Monthly Active Users (MAU, количество уникальных пользователей в месяц) и Daily Active Users (DAU, количество уникальных пользователей в день) – это отличные индикаторы здоровья цифрового продукта в целом. Если мы заинтересованы в долгосрочном росте, то это те показатели, про которые нельзя забывать! Они помогают отслеживать, растет база пользователей или нет, и то, насколько «залипательным» оказывается наш продукт для конечных пользователей.
  - Коэффициент конверсии - эта метрика поможет определить ключевые точки отсева пользователей и функции, которые могут работать некорректно. Конечно, найти нашу новую функцию они смогут, но трудно понять, какую ценность она несет для пользователей, если они ей не пользуются.
  - Churn (отток) и Customer Retention Rate проанализировать отток пользователей. Но нужно не забывать, что отток – это не всегда плохо. Возможно, наш продукт – это инструмент для поиска работы, который пользователь удалит, как только найдёт работу своей мечты. Всю историю нам покажет скорость оттока, и именно за ней и нужно следить.
  - Индексы Net Promoter Score (NPS) и Customer Satisfaction Score (CSAT) – отличный способ измерить настроение наших пользователей. Вкратце, наш показатель NPS скажет нам, насколько наш продукт нравится пользователям. Он поможет нам разделить пользователей на 3 категории в зависимости о того, на сколько баллов из 10 они оценят наш продукт. CSAT – это более простая оценка, ее можно использовать для понимания того, насколько пользователи довольны отдельными процессами или функциями. NPS чаще используется для измерения того, насколько пользователи довольны своим User Journey, тогда как CSAT даст нам больше конкретики. 
    - 1-6 = Критики. Такие люди используют наш продукт, но только по необходимости/из-за отсутствия альтернатив, и не порекомендовали бы его другу.
    - 7-8 = Пассивные клиенты. Этим людям нравится наш продукт, но он их не впечатлил.
    - 9-10 = Промоутеры. Такие люди – золотая жила. Они наши первые поклонники и будут активно продвигать наш продукт в своих кругах.
